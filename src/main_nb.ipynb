{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import get_ipython\n",
    "\n",
    "ipython = get_ipython()\n",
    "\n",
    "exec_no = ipython.execution_count\n",
    "exec_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random \n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from IPython.utils import io\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder\n",
    "from sklearn.cluster import DBSCAN, KMeans, AgglomerativeClustering\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.base import clone\n",
    "\n",
    "#!pip install -U git+https://github.com/joaopfonseca/SOMPY.git\n",
    "import sompy\n",
    "from sompy.visualization.mapview import View2D\n",
    "from sompy.visualization.bmuhits import BmuHitsView\n",
    "from sompy.visualization.hitmap import HitMapView\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina' # optionally, you can change 'svg' to 'retina'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: \n",
    "    with io.capture_output() as captured:\n",
    "        %run get_wd.py\n",
    "\n",
    "    s = captured.stdout # prints stdout from your script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if exec_no == 1: \n",
    "    s = os.getcwd()\n",
    "    os.chdir(os.path.dirname(s))\n",
    "    exec_no += 1\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definitions \n",
    "\n",
    "#os.chdir('/Users/dp/Nova/OneDrive - NOVAIMS/1stSemester/DM/DMProject')\n",
    "computed_data_path = 'computed_data/'\n",
    "explorations_data_path = 'explorations/'\n",
    "\n",
    "paths = [computed_data_path, explorations_data_path]\n",
    "for path in paths:\n",
    "    if not os.path.exists(path): \n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run promo_history.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "\n",
    "with open(os.path.join(computed_data_path, 'history_feat_raw.pickle'), 'rb') as f: \n",
    "    history_agg = pickle.load(f)\n",
    "    \n",
    "with open(os.path.join(computed_data_path, 'history_feat_multi_out.pickle'), 'rb') as f: \n",
    "    history_agg_out_multi = pickle.load(f)\n",
    "    \n",
    "with open(os.path.join(computed_data_path, 'history_feat_multi_clean.pickle'), 'rb') as f: \n",
    "    history_agg_multi = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_agg_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_agg_out_multi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cols\n",
    "\n",
    "## cols for clsutering \n",
    "cl_feat_hist = history_agg_multi.columns.to_list()\n",
    "print('\\ncl_feat_hist: \\n',cl_feat_hist)\n",
    "\n",
    "metric_features = cl_feat_hist\n",
    "\n",
    "## cols for descirption \n",
    "#desc_feat_hist = history_agg.loc[~history_agg.columns.isin(cl_feat_hist),:].columns.to_list()\n",
    "desc_feat_hist = history_agg.columns[~history_agg.columns.isin(cl_feat_hist)].to_list()\n",
    "print('\\ndesc_feat_hist: \\n',desc_feat_hist)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define rows\n",
    "\n",
    "cl_donor_ids = history_agg_multi.index.to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_agg[history_agg.index.isin(cl_donor_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hist = history_agg_multi[cl_feat_hist]\n",
    "df_hist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_df(df, scale='minmax'): \n",
    "    if scale == 'minmax': \n",
    "        scaler = MinMaxScaler()\n",
    "    df_normal = scaler.fit_transform(df)\n",
    "    df_normal = pd.DataFrame(df_normal, columns=df.columns, index=df.index)\n",
    "    return df_normal\n",
    "\n",
    "    \n",
    "df_hist_normal = scale_df(df=df_hist, scale='minmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normal = df_hist_normal.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multivariate outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the right clustering (algorithm and number of clusters) for each perspective\n",
    "kmeans_prod = KMeans(\n",
    "    n_clusters=10,\n",
    "    init='k-means++',\n",
    "    n_init=20,\n",
    "    random_state=1\n",
    ")\n",
    "hist_labels = kmeans_prod.fit_predict(df_hist_normal)\n",
    "\n",
    "df_normal['hist_labels'] = hist_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hist_normal.hist_labels.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on K-means and Hierarchical clustering\n",
    "Based on (1) our previous tests and (2) the context of this problem, the optimal number of clusters is expected to be between 3 and 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ss(df):\n",
    "    \"\"\"Computes the sum of squares for all variables given a dataset\n",
    "    \"\"\"\n",
    "    ss = np.sum(df.var() * (df.count() - 1))\n",
    "    return ss  # return sum of sum of squares of each df variable\n",
    "\n",
    "def r2(df, labels):\n",
    "    sst = get_ss(df)\n",
    "    ssw = np.sum(df.groupby(labels).apply(get_ss))\n",
    "    return 1 - ssw/sst\n",
    "    \n",
    "def get_r2_scores(df, clusterer, min_k=2, max_k=10):\n",
    "    \"\"\"\n",
    "    Loop over different values of k. To be used with sklearn clusterers.\n",
    "    \"\"\"\n",
    "    r2_clust = {}\n",
    "    for n in range(min_k, max_k):\n",
    "        clust = clone(clusterer).set_params(n_clusters=n)\n",
    "        labels = clust.fit_predict(df)\n",
    "        r2_clust[n] = r2(df, labels)\n",
    "    return r2_clust\n",
    "\n",
    "\n",
    "# Set up the clusterers\n",
    "kmeans = KMeans(\n",
    "    init='k-means++',\n",
    "    n_init=20,\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "hierarchical = AgglomerativeClustering(\n",
    "    affinity='euclidean'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the optimal clusterer on promotion history variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining the R² scores for each cluster solution on promotion history variables\n",
    "find_hist_k = False\n",
    "if find_hist_k:\n",
    "    r2_scores = {}\n",
    "    \n",
    "    print('kmeans')\n",
    "    r2_scores['kmeans'] = get_r2_scores(df_hist_normal, kmeans)\n",
    "\n",
    "    if False: \n",
    "        for linkage in ['ward']: # 'complete', 'average', 'single',\n",
    "            print(linkage)\n",
    "            r2_scores[linkage] = get_r2_scores(\n",
    "                df_hist_normal, hierarchical.set_params(linkage=linkage)\n",
    "            )\n",
    "\n",
    "    pd.DataFrame(r2_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the R² scores for each cluster solution on demographic variables\n",
    "if find_hist_k:\n",
    "    pd.DataFrame(r2_scores).plot.line(figsize=(10,7))\n",
    "\n",
    "    plt.title(\"Demographic Variables:\\nR² plot for various clustering methods\\n\", fontsize=21)\n",
    "    plt.legend(title=\"Cluster methods\", title_fontsize=11)\n",
    "    plt.xlabel(\"Number of clusters\", fontsize=13)\n",
    "    plt.ylabel(\"R² metric\", fontsize=13)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intertia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inertia = False\n",
    "\n",
    "if inertia:\n",
    "    range_clusters = range(1, 11)\n",
    "    inertia = []\n",
    "    for n_clus in range_clusters:  # iterate over desired ncluster range\n",
    "        print(n_clus)\n",
    "        kmclust = KMeans(n_clusters=n_clus, init='k-means++', n_init=20, random_state=1)\n",
    "        kmclust.fit(df_normal[cl_feat_hist])\n",
    "        inertia.append(kmclust.inertia_)  # save the inertia of the given cluster solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if inertia:\n",
    "    plt.plot(inertia)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This som implementation does not have a random seed parameter\n",
    "# We're going to set it up ourselves\n",
    "np.random.seed(42)\n",
    "\n",
    "# Notice that the SOM did not converge - We're under a time constraint for this class\n",
    "sm = sompy.SOMFactory().build(\n",
    "    df[metric_features].values, \n",
    "    mapsize=(50, 50), \n",
    "    initialization='random',\n",
    "    neighborhood='gaussian',\n",
    "    training='batch',\n",
    "    lattice='hexa',\n",
    "    component_names=metric_features\n",
    ")\n",
    "sm.train(n_job=-1, verbose='info', train_rough_len=100, train_finetune_len=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coordinates of the units in the input space\n",
    "sm.get_node_vectors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Component planes on the 50x50 grid\n",
    "sns.set()\n",
    "view2D = View2D(12,12,\"\", text_size=10)\n",
    "view2D.show(sm, col_sz=3, what='codebook')\n",
    "plt.subplots_adjust(top=0.90)\n",
    "plt.suptitle(\"Component Planes\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-matrix of the 50x50 grid\n",
    "u = sompy.umatrix.UMatrixView(12, 12, 'umatrix', show_axis=True, text_size=8, show_text=True)\n",
    "\n",
    "UMAT = u.show(\n",
    "    sm, \n",
    "    distance2=1, \n",
    "    row_normalized=False, \n",
    "    show_data=False, \n",
    "    contooor=True # Visualize isomorphic curves\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster visualization using t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_name = 'hist_labels' # 'merged_labels'\n",
    "\n",
    "tsne_df = df_normal.sample(frac=.1, axis=0, random_state=1)\n",
    "tsne_feat = tsne_df[metric_features]\n",
    "tsne_feat\n",
    "\n",
    "tsne_c = tsne_df[label_name]\n",
    "tsne_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is step can be quite time consuming\n",
    "\n",
    "two_dim = TSNE(random_state=1, n_jobs=-1).fit_transform(tsne_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE visualization\n",
    "pd.DataFrame(two_dim).plot.scatter(x=0, y=1, c=tsne_c, colormap='tab10', figsize=(15,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE visualization\n",
    "pd.DataFrame(two_dim).plot.scatter(x=0, y=1, c=tsne_c, colormap='tab10', figsize=(15,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
